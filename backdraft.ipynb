{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fe764e79-7a54-4f71-b357-0c1e10d7aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict; from dash import ALL, dcc, html, Input, MATCH, Output, State;\n",
    "from flask import Markup; from IPython.display import display, Markdown;\n",
    "from matplotlib.ticker import MaxNLocator; from plotly.subplots import make_subplots;\n",
    "from plotly.tools import mpl_to_plotly; from sklearn.metrics import accuracy_score, roc_curve, auc;\n",
    "from scipy.stats import pearsonr,spearmanr; from tensorflow.keras import layers, models, losses; \n",
    "from torch.utils.data import TensorDataset, DataLoader;\n",
    "import dash; import math; import matplotlib.pyplot as plt; import networkx as nx; import numpy as np;\n",
    "import numpy.random as rnd; import pandas as pd; import os; import PIL; import plotly.express as px;\n",
    "import plotly.graph_objects as go; import requests as rq; import seaborn as sns; import sklearn as skl; \n",
    "import sklearn.linear_model as lm; import statsmodels as sm; import statsmodels.api as sma; \n",
    "import statsmodels.formula.api as smf; import requests as rq; import tensorflow as tf; import torch; \n",
    "import torch.nn as nn; import torch.nn.functional as F; import torch.optim as optim; import torchvision; \n",
    "import torchvision.transforms as transforms; import urllib.request; import warnings;\n",
    "\n",
    "# file settings\n",
    "warnings.simplefilter(action='ignore', category=Warning); sns.set(); np.set_printoptions(threshold=np.inf); \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.max_columns', 12);  \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.width', 200);\n",
    "\n",
    "# global settings\n",
    "MRL = 3; #Measure Rounding Level\n",
    "folder = \"datasources\"; files = [\"datafile.csv\",\"schema.csv\",\"measures.csv\",\"propositions.csv\"]\n",
    "subtitles = {'Title1':\"Thakor Lab\",\n",
    "\t\t\t'Title2':\"Cerebrovascular Autoregulation and Post-Cardiac Arrest Resuscitation Therapies Team\",\n",
    "\t\t\t'Title3':\"Statistical Analysis GUI, v1.0\",\n",
    "\t\t\t'Step00':\"Select Response Variable: \", 'Step04':\"Check Predictor Variable(s) to test: \",\n",
    "\t\t\t'Step06':\"Select Measures to Display: \", 'Step07':\"Select Model Proposition to Calculate: \",\n",
    "\t\t\t'Step09':\"Enter the Configuration Settings for the selected model (default values pre-entered): \",\n",
    "\t\t\t'Step09.01':\"Random Seed: \", 'Step09.02':\"Percent of Data to use in Training vs Testing: \",\n",
    "\t\t\t'Step09.03':\"Include Intercept value in Model: \", 'Step09.04':\"Magnitude of Iteration Limit: \",\n",
    "\t\t\t'Step09.05':\"Percentile to use as Threshold for Binarization of Response Variable: \", \n",
    "\t\t\t'Step09.06':\"Number of Layers in Model: \", 'Step09.07':\"Branches or Nodes per Layers of Model: \",\n",
    "\t\t\t'Step09.08':\"Learning Rate of Model: \",\n",
    "\t\t\t'Step12.01':\"Histogram of Response Variable Values\", 'Step12.02':\"Histogram(s) of Predictor Variable Values\",\n",
    "\t\t\t'Step13':\"Table of Requested Measure(s)\",'Step14':\"Details of Requested Model\"};\n",
    "\n",
    "# globalized variables:\n",
    "# df_Raw; df_Schema; df_Meas; df_Prop;\n",
    "# namesPred; namesResp; namesMeas; namesProp;\n",
    "# uniList\n",
    "\n",
    "# BEGIN LOGIC FUNCTIONS\n",
    "def loadData():\n",
    "#. load data files into memory\n",
    "\tglobal df_Raw; df_Raw = pd.read_csv(folder+'/'+files[0]);\n",
    "\tglobal df_Schema; df_Schema = pd.read_csv(folder+'/'+files[1]);\n",
    "\tglobal namesResp; namesResp = genFieldDict('Response',df_Schema); \n",
    "\tglobal namesPred; namesPred = genFieldDict('Predictor',df_Schema);\n",
    "\tglobal df_Meas; df_Meas = pd.read_csv(folder+'/'+files[2]); \n",
    "\tglobal namesMeas; namesMeas = genFieldDict('Ready',df_Meas); \n",
    "\tglobal df_Prop; df_Prop = pd.read_csv(folder+'/'+files[3]);\n",
    "\tglobal namesProp; namesProp = genFieldDict('Ready',df_Prop);\n",
    "\tglobal uniList; uniList = genFieldDict('Variate',df_Meas);\n",
    "\t\n",
    "def genFieldDict(req,df):\n",
    "#. generate field dictionary from dataframe based on specified parameter flag\n",
    "    fieldlist = df.loc[(df[req]==1)].Column.to_numpy();\n",
    "    fieldDict = dict(enumerate(fieldlist.flatten(), 1));\n",
    "    #fieldDictInv = dict((v, k) for k, v in fieldDictInv.items());\n",
    "    return fieldDict;\n",
    "    \n",
    "def genMeas(varResp, varPred, varMeas):\n",
    "# pull specified values from data sources -> pass to measure switch -> pass back to view\n",
    "\tretResp = {}; retVal = {}; measList = []; \n",
    "\tfor meas in varMeas:\n",
    "\t\tmeasList.append(namesMeas[meas]);\n",
    "\trespVals = df_Raw[namesResp[varResp]];     \n",
    "\tfor meas in measList:\n",
    "\t\tif (meas in uniList.values()):\n",
    "\t\t\tretResp[meas] = calcSwitch(meas,respVals);\n",
    "\tif (len(varPred)>0):\n",
    "\t\tpredDict = {};\n",
    "\t\tfor varP in varPred:\n",
    "\t\t\tpredName = namesPred[varP];\n",
    "\t\t\tpredVals = df_Raw[predName];\n",
    "\t\t\tretPredCurr = {}; \n",
    "\t\t\tfor meas in measList:\n",
    "\t\t\t\tif (meas in uniList.values()):\n",
    "\t\t\t\t\tretPredCurr[meas] = calcSwitch(meas,predVals);\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tretPredCurr[meas] = calcSwitch(meas,predVals,respVals);            \n",
    "\t\t\tpredDict[predName] = retPredCurr;\n",
    "\t\t\tretVal['pred'] = predDict;\n",
    "\tretVal['resp'] = retResp;\n",
    "\treturn retVal;\n",
    "\n",
    "def calcSwitch(measName,varA,varB=[]):\n",
    "# identify measure -> pass values to measure-specific function -> format result as single string -> pass back to view\n",
    "\tretVal = '';\n",
    "\tif (measName=='Mean'):\n",
    "\t\tretVal = calcMean(varA);\n",
    "\telif (measName=='Std'):\n",
    "\t\tretVal = calcStd(varA);\n",
    "\telif (measName=='Correlation-Pearson'):\n",
    "\t\tval,pval = calcCorrP(varA,varB);        \n",
    "\t\tretVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "\telif (measName=='Correlation-Spearman'):\n",
    "\t\tval,pval = calcCorrS(varA,varB);\n",
    "\t\tretVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "\treturn retVal;\n",
    "\n",
    "# BEGIN MEASURE-SPECIFIC FUNCTIONS\n",
    "def calcMean(varList):\n",
    "    return round(np.mean(varList),MRL);\n",
    "\n",
    "def calcStd(varList):\n",
    "    return round(np.std(varList),MRL);\n",
    "\n",
    "def calcCorrP(varA,varB):\n",
    "\tretV, retP = pearsonr(varA,varB); \n",
    "\tretV = round(retV,MRL);\n",
    "\tretP = round(retP,MRL);\n",
    "\treturn [retV,retP];\n",
    "\n",
    "def calcCorrS(varA,varB):\n",
    "\tretV, retP = spearmanr(varA,varB); \n",
    "\tretV = round(retV,MRL);\n",
    "\tretP = round(retP,MRL);\n",
    "\treturn [retV,retP];\n",
    "# END MEASURE-SPECIFIC FUNCTIONS\n",
    "\t\t\t\t\t\t\t\t \n",
    "def genModel(varResp, varPred, varProp, d_Conf):\n",
    "# pull specified values from data sources -> pass to model switch -> pass back to view\n",
    "    retVal = {}; \n",
    "    respName = namesResp[varResp]; valsResp = df_Raw[respName];\n",
    "    valsPred = pd.DataFrame(); \n",
    "    for varP in varPred:\n",
    "        predName = namesPred[varP];\n",
    "        valsPred[predName] = df_Raw[predName];\n",
    "    propName = namesProp[varProp];\n",
    "    retVal = modelSwitch(propName,valsResp,valsPred,d_Conf);\n",
    "    return retVal;\n",
    "\n",
    "def modelSwitch(propName,valsResp,valsPred,d_Conf):\n",
    "# identify proposition -> pass values and configuration to proposition-specific function -> calculate error rates -> pass back to view\n",
    "\tretVal = {};\n",
    "\tnp.random.seed(d_Conf['Seed']); sample = np.random.uniform(size = len(valsResp.index)) < d_Conf['TrainPct'];\n",
    "\ttrainResp = valsResp[sample]; testResp = valsResp[~sample];\n",
    "\ttrainPred = valsPred[sample]; testPred = valsPred[~sample];\n",
    "\tif (propName=='Linear-Regression'):\n",
    "\t\tretVal['model'] = modelLinReg(trainResp,trainPred,d_Conf);\n",
    "\t\tmodTrain = retVal['model'].predict(trainPred);\n",
    "\t\tmodTest = retVal['model'].predict(testPred);\n",
    "\t\tretVal['error'] = {};\n",
    "\t\tretVal['error']['train'] = assessErr(trainResp.to_numpy(),modTrain);\n",
    "\t\tretVal['error']['test'] = assessErr(testResp.to_numpy(),modTest);\n",
    "\telif (propName=='Logistic-Regression'):\n",
    "\t\tthresh = np.percentile(valsResp,d_Conf['BinThresh']);\n",
    "\t\ttrainResp = (trainResp > thresh).astype(int); \n",
    "\t\ttestResp = (testResp > thresh).astype(int); \n",
    "\t\tretVal['model'] = modelLogReg(trainResp,trainPred,d_Conf);\n",
    "\t\tmodTrain = retVal['model'].predict(trainPred);\n",
    "\t\tmodTest = retVal['model'].predict(testPred);\n",
    "\t\tretVal['error'] = {}; retVal['roc'] = {};\n",
    "\t\tretVal['roc']['train'] = assessAUC(trainResp.to_numpy(),modTrain);\n",
    "\t\tretVal['roc']['test'] = assessAUC(testResp.to_numpy(),modTest);\n",
    "\t\tretVal['error']['train'] = assessErr(trainResp.to_numpy(),modTrain,True);\n",
    "\t\tretVal['error']['test'] = assessErr(testResp.to_numpy(),modTest,True);\n",
    "\telif (propName=='Neural-Network'):\n",
    "\t\tmodel = modelNN(trainResp,trainPred,d_Conf);\n",
    "\t\tretVal['model'] = model;\n",
    "\t\tmodTrain = model(convNNType(trainPred)).detach().numpy().T[0];\n",
    "\t\tmodTest =  model(convNNType(testPred)).detach().numpy().T[0];\n",
    "\t\tretVal['error'] = {};\n",
    "\t\tretVal['error']['train'] = assessErr(trainResp.to_numpy(),modTrain);\n",
    "\t\tretVal['error']['test'] = assessErr(testResp.to_numpy(),modTest);\n",
    "\treturn retVal;\n",
    "\n",
    "# BEGIN PROPOSITION-SPECIFIC FUNCTIONS\n",
    "def modelLinReg(resp,pred,d_Conf):\n",
    "    model = lm.LinearRegression(fit_intercept=d_Conf['Intercept']).fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelLogReg(resp,pred,d_Conf):\n",
    "    model = lm.LogisticRegression(fit_intercept=d_Conf['Intercept'],max_iter=d_Conf['Magnitude']).fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def convNNType(df):\n",
    "    return torch.from_numpy(df.values).float();\n",
    "\n",
    "def modelNN(rdat,pdat,d_Conf):\n",
    "    pdat = convNNType(pdat); rdat = convNNType(rdat);\n",
    "    inSz = pdat.shape[1]; outSz = 1;\n",
    "    modelGraph = OrderedDict([('inLayer', nn.Linear(inSz,d_Conf['Nodes'])),('relu1', nn.ReLU())]);\n",
    "    if (d_Conf['Layers']>1):\n",
    "        for idx in range(1,d_Conf['Layers']):\n",
    "            modelGraph['hl'+str(idx)] = nn.Linear(d_Conf['Nodes'],d_Conf['Nodes']); \n",
    "            modelGraph['relu'+str(1+idx)] = nn.ReLU();\n",
    "    modelGraph['outLayer'] = nn.Linear(d_Conf['Nodes'],outSz); model = nn.Sequential(modelGraph);    \n",
    "    model.zero_grad(); lossFn = nn.MSELoss(reduction='sum');\n",
    "    optim = torch.optim.Adam(model.parameters(), d_Conf['LearnRate']);\n",
    "    for idx in range(d_Conf['Magnitude']):\n",
    "        currPred = model(pdat); currLoss = lossFn(currPred,rdat);\n",
    "        optim.zero_grad(); currLoss.backward(); optim.step();\n",
    "    return model; \n",
    "# END PROPOSITION-SPECIFIC FUNCTIONS\n",
    "\n",
    "def assessErr(truth,prediction,bindata=False):\n",
    "    if (bindata): # Percent Error\n",
    "        retVal = sum(abs(np.subtract(truth,prediction))/len(truth));\n",
    "    else: # RMS Error\n",
    "        retVal = round(math.sqrt(sum((np.subtract(truth,prediction))**2)/len(truth)),2);\n",
    "    return retVal; \n",
    "\n",
    "def assessAUC(truth,prediction):\n",
    "    fpr, tpr, thresh = roc_curve(truth,prediction); calcAUC = auc(fpr, tpr); \n",
    "    return [fpr,tpr,calcAUC];\n",
    "\n",
    "def makeROC(inDict,title):\n",
    "\tfig = go.Figure();\n",
    "\tfig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], line={'color':'navy','width':2}));\n",
    "\tfig.add_trace(go.Scatter(x=inDict[0], y=inDict[1], line={'color':'darkorange','width':2,'dash':'dash'}));\n",
    "\tfig.update_layout(title=('ROC curve (area = '+str(round(inDict[2],MRL))+') for '+title)\n",
    "                   ,xaxis_title='False Positive Rate'\n",
    "                   ,yaxis_title='True Positive Rate')\n",
    "\treturn fig;\n",
    "\n",
    "def setDiff(listA,listB):\n",
    "    return list(set(listA) - set(listB));\n",
    "\n",
    "def setInt(listA,listB):\n",
    "    return list(set(listA) & set(listB));\n",
    "# END LOGIC FUNCTIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d22524fb-1e15-4153-bee7-7246ea79d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadData(); \n",
    "selResp=1; selPred = [1,3]; selMeas=[2,3]; selProp=2;\n",
    "confSeed=123; confTPct=50; confInt=1; confMag=4;\n",
    "confBThr=50; confLyrs=2; confNodes=2; confLR=2;\n",
    "d_Conf = {}; d_Conf['Seed'] = confSeed; \n",
    "d_Conf['TrainPct'] = confTPct/100; d_Conf['Intercept'] = (confInt==1); \n",
    "d_Conf['Magnitude'] = int(1*10**confMag); d_Conf['BinThresh'] = confBThr; \n",
    "d_Conf['Layers'] = confLyrs; d_Conf['Nodes'] = confNodes; d_Conf['LearnRate'] = float(1*10**(-int(confLR))); \n",
    "retVal = genModel(selResp,selPred,selProp,d_Conf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ca1e1-a9c9-44e4-82b5-6dee337dbc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
