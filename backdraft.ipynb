{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea43f66-e85f-4409-9a38-cb7c231e765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict; from dash import ALL, dcc, html, Input, MATCH, Output, State;\n",
    "from flask import Markup; from IPython.display import display, Markdown;\n",
    "from matplotlib.ticker import MaxNLocator; from plotly.subplots import make_subplots;\n",
    "from plotly.tools import mpl_to_plotly; from sklearn import svm,tree;\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc;\n",
    "from scipy.stats import iqr,kurtosis,median_abs_deviation,mode,pearsonr,spearmanr,skew; \n",
    "from tensorflow.keras import layers, models, losses; \n",
    "from torch.utils.data import TensorDataset, DataLoader;\n",
    "import dash; import dash_useful_components as duc; import graphviz; import math; import matplotlib.pyplot as plt; \n",
    "import networkx as nx; import numpy as np; import numpy.random as rnd; import pandas as pd;\n",
    "import os; import plotly.express as px; import plotly.graph_objects as go; import requests as rq;\n",
    "import seaborn as sns; import sklearn as skl; import sklearn.linear_model as lm; \n",
    "import sklearn.naive_bayes as nb; import sklearn.discriminant_analysis as lda; \n",
    "import statistics as stttx; import statsmodels as sm; import statsmodels.api as sma; \n",
    "import statsmodels.formula.api as smf; import requests as rq; import tensorflow as tf; \n",
    "import torch; import torch.nn as nn; import torch.nn.functional as F; import torch.optim as optim; \n",
    "import torchvision; import torchvision.transforms as transforms; import urllib.request; import warnings;\n",
    "\n",
    "# file settings\n",
    "warnings.simplefilter(action='ignore', category=Warning); sns.set(); np.set_printoptions(threshold=np.inf); \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.max_columns', 12);  \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.width', 200);\n",
    "\n",
    "# global settings\n",
    "MRL = 3; #Measure Rounding Level\n",
    "folder = \"datasources\"; files = [\"cohorts.csv\",\"datafile.csv\",\"measures.csv\",\"propositions.csv\",\"schema.csv\"]\n",
    "subtitles = {'Title1':\"Thakor Lab\",\n",
    "            'Title2':\"Cerebrovascular Autoregulation and Post-Cardiac Arrest Resuscitation Therapies Team\",\n",
    "            'Title3':\"Statistical Analysis GUI, v1.0\",\n",
    "            'Step00':\"Select Response Variable: \", 'Step04':\"Check Predictor Variable(s) to test: \",\n",
    "            'Step06':\"Select Measures to Display: \", 'Step07':\"Select Model Proposition to Calculate: \",\n",
    "            'Step09':\"Enter the Configuration Settings for the selected model (default values pre-entered): \",\n",
    "            'Step09.01':\"Random Seed: \", 'Step09.02':\"Percent of Data to use in Training vs Testing: \",\n",
    "            'Step09.03':\"Include Intercept value in Model: \", 'Step09.04':\"Magnitude of Iteration Limit: \",\n",
    "            'Step09.05':\"Percentile to use as Threshold for Binarization of Response Variable: \", \n",
    "            'Step09.06':\"Number of Layers in Model: \", 'Step09.07':\"Branches or Nodes per Layers of Model: \",\n",
    "            'Step09.08':\"Learning Rate of Model: \",\n",
    "            'Step12.01':\"Histogram of Response Variable Values\", 'Step12.02':\"Histogram(s) of Predictor Variable Values\",\n",
    "            'Step13':\"Table of Requested Measure(s)\",'Step14':\"Details of Requested Model\"};\n",
    "\n",
    "# globalized variables:\n",
    "# df_DataProc; df_Meas; df_Prop; df_Schema; \n",
    "# namesMeas; namesPred; namesProp; namesResp;\n",
    "# uniList\n",
    "\n",
    "def loadData():\n",
    "#. load data files into memory\n",
    "    global df_Cohorts; df_Cohorts = pd.read_csv(folder+'/'+files[0]); \n",
    "    global df_DataProc; df_DataProc = pd.read_csv(folder+'/'+files[1]);\n",
    "    global df_Meas; df_Meas = pd.read_csv(folder+'/'+files[2]); \n",
    "    global df_Prop; df_Prop = pd.read_csv(folder+'/'+files[3]);\n",
    "    global df_Schema; df_Schema = pd.read_csv(folder+'/'+files[4]);\n",
    "    global namesResp; namesResp = genFieldDict(['Response'],df_Schema); \n",
    "    global namesPred; namesPred = genFieldDict(['Predictor'],df_Schema);\n",
    "    global namesMeas; namesMeas = genFieldDict(['Ready'],df_Meas); \n",
    "    global namesProp; namesProp = genFieldDict(['Ready'],df_Prop);\n",
    "    global uniList; uniList = genFieldDict(['Variate'],df_Meas);\n",
    "\n",
    "def genFieldDict(reqList,df):\n",
    "#. generate field dictionary from dataframe based on specified parameter flag(s)\n",
    "    reqQuery = buildQuery(reqList);\n",
    "    fieldlist = df.query(reqQuery).Column.to_numpy();\n",
    "    fieldDict = dict(enumerate(fieldlist.flatten(), 1));\n",
    "    #fieldDictInv = dict((v, k) for k, v in fieldDictInv.items());\n",
    "    return fieldDict;\n",
    "    \n",
    "def buildQuery(colList,valList = [1], ander=True):\n",
    "    conj = \" and \" if ander else \" or \";\n",
    "    offset = len(conj); query = \"\"; eqstr = \" == \";\n",
    "    if (len(colList)>1):\n",
    "        if (len(valList)>1):\n",
    "            queryDict = dict(zip(colList,valList));\n",
    "        else:\n",
    "            queryDict = dict(zip(colList,valList*len(colList)));\n",
    "        for k,v in queryDict.items():\n",
    "            query = query + conj + k + eqstr + str(v);\n",
    "        query = query[offset:(len(query)-offset)];\n",
    "    else:\n",
    "        query = str(colList[0]) + eqstr + str(valList[0]);\n",
    "    return query;\n",
    "    \n",
    "def genMeas(varResp, varPred, varMeas):\n",
    "# pull specified values from data sources -> pass to measure switch -> pass back to view\n",
    "    retResp = {}; retVal = {}; measList = []; \n",
    "    for meas in varMeas:\n",
    "        measList.append(namesMeas[meas]);\n",
    "    respVals = df_DataProc[namesResp[varResp]];     \n",
    "    for meas in measList:\n",
    "        if (meas in uniList.values()):\n",
    "            retResp[meas] = calcSwitch(meas,respVals);\n",
    "    if (len(varPred)>0):\n",
    "        predDict = {};\n",
    "        for varP in varPred:\n",
    "            predName = namesPred[varP];\n",
    "            predVals = df_DataProc[predName];\n",
    "            retPredCurr = {}; \n",
    "            for meas in measList:\n",
    "                if (meas in uniList.values()):\n",
    "                    retPredCurr[meas] = calcSwitch(meas,predVals);\n",
    "                else:\n",
    "                    retPredCurr[meas] = calcSwitch(meas,predVals,respVals);            \n",
    "            predDict[predName] = retPredCurr;\n",
    "            retVal['pred'] = predDict;\n",
    "    retVal['resp'] = retResp;\n",
    "    return retVal;\n",
    "\n",
    "def calcSwitch(measName,varA,varB=[]):\n",
    "# identify measure -> pass values to measure-specific function -> format result as single string -> pass back to view\n",
    "    retVal = '';\n",
    "# Bivariate Measures\n",
    "    if (measName=='Chi-Squared-Independence'):\n",
    "        val,pval = calcChiSq(varA,varB);        \n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Correlation-Pearson'):\n",
    "        val,pval = calcCorrP(varA,varB);        \n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Correlation-Spearman'):\n",
    "        val,pval = calcCorrS(varA,varB);\n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Covariance'):\n",
    "        retVal = calcCovar(varA,varB);\n",
    "# Univariate Measures\n",
    "    elif (measName=='Interquartile-Range'):\n",
    "        retVal = calcIQR(varA);\n",
    "    elif (measName=='Kurtosis'):\n",
    "        retVal = calcKurtosis(varA);\n",
    "    elif (measName=='Maximum'):\n",
    "        retVal = calcMax(varA);\n",
    "    elif (measName=='Mean'):\n",
    "        retVal = calcMean(varA);\n",
    "    elif (measName=='Median'):\n",
    "        retVal = calcMedian(varA);\n",
    "    elif (measName=='Median-Absolute-Deviation'):\n",
    "        retVal = calcMAD(varA);\n",
    "    elif (measName=='Minimum'):\n",
    "        retVal = calcMin(varA);\n",
    "    elif (measName=='Mode'):\n",
    "        retVal = calcMode(varA);\n",
    "    elif (measName=='Normality'):\n",
    "        val,pval = calcNormality(varA,varB);\n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Range'):\n",
    "        retVal = calcRange(varA);\n",
    "    elif (measName=='Relative-Standard-Deviation'):\n",
    "        retVal = calcRSD(varA);\n",
    "    elif (measName=='Skew'):\n",
    "        retVal = calcSkew(varA);\n",
    "    elif (measName=='Standard-Deviation'):\n",
    "        retVal = calcStd(varA);\n",
    "    return retVal;\n",
    "\n",
    "# BEGIN MEASURE-SPECIFIC FUNCTIONS\n",
    "# BEGIN BIVARIATE MEASURES\n",
    "def calcChiSq(varA,varB):\n",
    "    retV, retP, _, _ = chi2_contingency(np.array([varA,varB]), correction=False);\n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCorrP(varA,varB):\n",
    "    retV, retP = pearsonr(varA,varB); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCorrS(varA,varB):\n",
    "    retV, retP = spearmanr(varA,varB); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCovar(varA,varB):\n",
    "    return round(np.cov(a,b)[0][1],MRL);\n",
    "\n",
    "# END BIVARIATE MEASURES\n",
    "# BEGIN UNIVARIATE MEASURES\n",
    "def calcIQR(varList):\n",
    "    return round(iqr(varList),MRL);\n",
    "\n",
    "def calcKurtosis(varList):\n",
    "    return round(kurtosis(varList),MRL);\n",
    "\n",
    "def calcMax(varList):\n",
    "    return round(max(varList),MRL);\n",
    "\n",
    "def calcMedian(varList):\n",
    "    return round(stttx.median(varList),MRL);\n",
    "\n",
    "def calcMAD(varList):\n",
    "    return round(median_abs_deviation(varList),MRL);\n",
    "\n",
    "def calcMean(varList):\n",
    "    return round(np.mean(varList),MRL);\n",
    "\n",
    "def calcMin(varList):\n",
    "    return round(min(varList),MRL);\n",
    "\n",
    "def calcMode(varList): \n",
    "    return round(mode(varList),MRL);\n",
    "\n",
    "def calcNormality(varList): #TODO\n",
    "    retV, retP = spearmanr(varList); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcRange(varList):\n",
    "    return round(calcMax(varList)-calcMin(varList),MRL);\n",
    "\n",
    "def calcRSD(varList):\n",
    "    return round(calcStd(varList)/calcMean(varList),MRL);\n",
    "\n",
    "def calcSkew(varList):\n",
    "    return round(skew(varList),MRL);\n",
    "\n",
    "def calcStd(varList):\n",
    "    return round(np.std(varList),MRL);\n",
    "# END UNIVARIATE MEASURES\n",
    "# END MEASURE-SPECIFIC FUNCTIONS\n",
    "\n",
    "def genModel(varResp, varPred, varProp, d_Conf):\n",
    "# pull specified values from data sources -> pass to model switch -> pass back to view\n",
    "    retVal = {}; \n",
    "    respName = namesResp[varResp]; valsResp = df_DataProc[respName];\n",
    "    valsPred = pd.DataFrame(); \n",
    "    for varP in varPred:\n",
    "        predName = namesPred[varP];\n",
    "        valsPred[predName] = df_DataProc[predName];\n",
    "    propName = namesProp[varProp];\n",
    "    retVal = modelSwitch(propName,valsResp,valsPred,d_Conf);\n",
    "    return retVal;\n",
    "\n",
    "def modelSwitch(propName,valsResp,valsPred,d_Conf):\n",
    "# identify proposition -> pass values and configuration to proposition-specific function -> calculate error rates -> pass back to view\n",
    "# TODO Display: Scatter plot(s) for Proposition:Linear Regression, Proposition:LDA, Proposition:SVM\n",
    "# Node-Graph for Proposition:Decision Tree and Proposition:Neural Network\n",
    "# Univariate: Box-and-whisker plot\n",
    "# Bivariate: Scatter Plots\n",
    "    retVal = {};\n",
    "    np.random.seed(d_Conf['Seed']); sample = np.random.uniform(size = len(valsResp.index)) < d_Conf['TrainPct'];\n",
    "    trainResp = valsResp[sample]; testResp = valsResp[~sample];\n",
    "    trainPred = valsPred[sample]; testPred = valsPred[~sample];\n",
    "    binclass = checkBinClass(propName);\n",
    "    if(binclass):\n",
    "        thresh = np.percentile(valsResp,d_Conf['BinThresh']);\n",
    "        trainResp = (trainResp > thresh).astype(int); \n",
    "        testResp = (testResp > thresh).astype(int); \n",
    "    if (propName=='Neural-Network'):\n",
    "        model = modelNN(trainResp,trainPred,d_Conf);\n",
    "        retVal['model'] = model;\n",
    "        modTrain = model(convNNType(trainPred)).detach().numpy().T[0];\n",
    "        modTest =  model(convNNType(testPred)).detach().numpy().T[0];\n",
    "    else:\n",
    "        if (propName=='Decision-Tree'):\n",
    "            retVal['model'] = modelDecTree(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Linear-Discriminant-Analysis'):\n",
    "            retVal['model'] = modelLDA(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Linear-Regression'):\n",
    "            retVal['model'] = modelLinReg(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Logistic-Regression'):\n",
    "            retVal['model'] = modelLogReg(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Naive-Bayes-Categorical'):\n",
    "            retVal['model'] = modelNBCat(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Naive-Bayes-Gaussian'):\n",
    "            retVal['model'] = modelNBGauss(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Support-Vector-Machine'):\n",
    "            retVal['model'] = modelSVM(trainResp,trainPred,d_Conf);\n",
    "        modTrain = retVal['model'].predict(trainPred);\n",
    "        modTest = retVal['model'].predict(testPred);\n",
    "    retVal['error'] = {};\n",
    "    retVal['error']['train'] = assessErr(trainResp.to_numpy(),modTrain,binclass);\n",
    "    retVal['error']['test'] = assessErr(testResp.to_numpy(),modTest,binclass);\n",
    "    if (binclass):\n",
    "        retVal['roc'] = {};\n",
    "        retVal['roc']['train'] = assessAUC(trainResp.to_numpy(),modTrain);\n",
    "        retVal['roc']['test'] = assessAUC(testResp.to_numpy(),modTest);\n",
    "    return retVal;\n",
    "\n",
    "# BEGIN PROPOSITION-SPECIFIC FUNCTIONS\n",
    "def modelDecTree(resp,pred,d_Conf):\n",
    "    model = tree.DecisionTreeClassifier(); \n",
    "    model.fit(pred,resp)\n",
    "    return model;\n",
    "\n",
    "def modelLDA(resp,pred,d_Conf):\n",
    "    model = lda.LinearDiscriminantAnalysis(tol=d_Conf['LearnRate']); \n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelLinReg(resp,pred,d_Conf):\n",
    "    model = lm.LinearRegression(fit_intercept=d_Conf['Intercept']);\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelLogReg(resp,pred,d_Conf):\n",
    "    model = lm.LogisticRegression(fit_intercept=d_Conf['Intercept'],max_iter=d_Conf['Magnitude']);\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelNBCat(resp,pred,d_Conf):\n",
    "    model = nb.CategoricalNB();\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelNBGauss(resp,pred,d_Conf):\n",
    "    model = nb.GaussianNB(); \n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelSVM(resp,pred,d_Conf):\n",
    "    model = svm.SVC(kernel='linear',max_iter=d_Conf['Magnitude'],tol=d_Conf['LearnRate']);\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def convNNType(df):\n",
    "    return torch.from_numpy(df.values).float();\n",
    "\n",
    "def modelNN(rdat,pdat,d_Conf):\n",
    "    pdat = convNNType(pdat); rdat = convNNType(rdat);\n",
    "    inSz = pdat.shape[1]; outSz = 1;\n",
    "    modelGraph = OrderedDict([('inLayer', nn.Linear(inSz,d_Conf['Nodes'])),('relu1', nn.ReLU())]);\n",
    "    if (d_Conf['Layers']>1):\n",
    "        for idx in range(1,d_Conf['Layers']):\n",
    "            modelGraph['hl'+str(idx)] = nn.Linear(d_Conf['Nodes'],d_Conf['Nodes']); \n",
    "            modelGraph['relu'+str(1+idx)] = nn.ReLU();\n",
    "    modelGraph['outLayer'] = nn.Linear(d_Conf['Nodes'],outSz); model = nn.Sequential(modelGraph);    \n",
    "    model.zero_grad(); lossFn = nn.MSELoss(reduction='sum');\n",
    "    optim = torch.optim.Adam(model.parameters(), d_Conf['LearnRate']);\n",
    "    for idx in range(d_Conf['Magnitude']):\n",
    "        currPred = model(pdat); currLoss = lossFn(currPred,rdat);\n",
    "        optim.zero_grad(); currLoss.backward(); optim.step();\n",
    "    return model; \n",
    "# END PROPOSITION-SPECIFIC FUNCTIONS\n",
    "\n",
    "def assessErr(truth,prediction,bindata=False):\n",
    "    if (bindata): # Percent Error\n",
    "        retVal = sum(abs(np.subtract(truth,prediction))/len(truth));\n",
    "    else: # RMS Error\n",
    "        retVal = round(math.sqrt(sum((np.subtract(truth,prediction))**2)/len(truth)),2);\n",
    "    return retVal; \n",
    "\n",
    "def assessAUC(truth,prediction):\n",
    "    fpr, tpr, thresh = roc_curve(truth,prediction); calcAUC = auc(fpr, tpr); \n",
    "    return [fpr,tpr,calcAUC];\n",
    "\n",
    "def makeROC(inDict,title):\n",
    "    fig = go.Figure();\n",
    "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], line={'color':'navy','width':2}));\n",
    "    fig.add_trace(go.Scatter(x=inDict[0], y=inDict[1], line={'color':'darkorange','width':2,'dash':'dash'}));\n",
    "    fig.update_layout(title=('ROC curve (area = '+str(round(inDict[2],MRL))+') for '+title)\n",
    "                   ,xaxis_title='False Positive Rate'\n",
    "                   ,yaxis_title='True Positive Rate')\n",
    "    return fig;\n",
    "\n",
    "def checkBinClass(propName):\n",
    "    return (df_Prop[df_Prop.Column==propName].Binthresh==1).reset_index()['Binthresh'][0];\n",
    "\n",
    "def setDiff(listA,listB):\n",
    "    return list(set(listA) - set(listB));\n",
    "\n",
    "def setInt(listA,listB):\n",
    "    return list(set(listA) & set(listB));\n",
    "# END LOGIC FUNCTIONS\n",
    "\n",
    "loadData(); print(namesProp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a8958-1cbf-406b-a685-80b185bcb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "selResp=1; selPred = [1,3]; selMeas=[2,3]; selProp=4;\n",
    "confSeed=123; confTPct=50; confInt=1; confMag=4;\n",
    "confBThr=50; confLyrs=2; confNodes=2; confLR=2;\n",
    "d_Conf = {}; d_Conf['Seed'] = confSeed; \n",
    "d_Conf['TrainPct'] = confTPct/100; d_Conf['Intercept'] = (confInt==1); \n",
    "d_Conf['Magnitude'] = int(1*10**confMag); d_Conf['BinThresh'] = confBThr; \n",
    "d_Conf['Layers'] = confLyrs; d_Conf['Nodes'] = confNodes; d_Conf['LearnRate'] = float(1*10**(-int(confLR))); \n",
    "retVal = genModel(selResp,selPred,selProp,d_Conf);\n",
    "print(retVal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
