{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea43f66-e85f-4409-9a38-cb7c231e765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict; from dash import ALL, dcc, html, Input, MATCH, Output, State;\n",
    "from flask import Markup; from IPython.display import display, Markdown;\n",
    "from matplotlib.ticker import MaxNLocator; from plotly.subplots import make_subplots;\n",
    "from plotly.tools import mpl_to_plotly; from sklearn import svm,tree;\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc;\n",
    "from scipy.stats import iqr,kurtosis,median_abs_deviation,mode,pearsonr,spearmanr,skew; \n",
    "from tensorflow.keras import layers, models, losses; \n",
    "from torch.utils.data import TensorDataset, DataLoader;\n",
    "import dash; import dash_useful_components as duc; import math; import matplotlib.pyplot as plt; \n",
    "import networkx as nx; import numpy as np; import numpy.random as rnd; import pandas as pd;\n",
    "import os; import PIL; import plotly.express as px; import plotly.graph_objects as go; \n",
    "import requests as rq; import seaborn as sns; import sklearn as skl; import sklearn.linear_model as lm; \n",
    "import sklearn.discriminant_analysis as lda; import statistics as stttx;\n",
    "import statsmodels as sm; import statsmodels.api as sma; import statsmodels.formula.api as smf; \n",
    "import requests as rq; import tensorflow as tf; import torch; import torch.nn as nn; \n",
    "import torch.nn.functional as F; import torch.optim as optim; import torchvision; \n",
    "import torchvision.transforms as transforms; import urllib.request; import warnings;\n",
    "\n",
    "# file settings\n",
    "warnings.simplefilter(action='ignore', category=Warning); sns.set(); np.set_printoptions(threshold=np.inf); \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.max_columns', 12);  \n",
    "pd.set_option('display.max_rows',999); pd.set_option('display.width', 200);\n",
    "\n",
    "# global settings\n",
    "MRL = 3; #Measure Rounding Level\n",
    "folder = \"datasources\"; files = [\"cohorts.csv\",\"datafile.csv\",\"measures.csv\",\"propositions.csv\",\"schema.csv\"]\n",
    "subtitles = {'Title1':\"Thakor Lab\",\n",
    "            'Title2':\"Cerebrovascular Autoregulation and Post-Cardiac Arrest Resuscitation Therapies Team\",\n",
    "            'Title3':\"Statistical Analysis GUI, v1.0\",\n",
    "            'Step00':\"Select Response Variable: \", 'Step04':\"Check Predictor Variable(s) to test: \",\n",
    "            'Step06':\"Select Measures to Display: \", 'Step07':\"Select Model Proposition to Calculate: \",\n",
    "            'Step09':\"Enter the Configuration Settings for the selected model (default values pre-entered): \",\n",
    "            'Step09.01':\"Random Seed: \", 'Step09.02':\"Percent of Data to use in Training vs Testing: \",\n",
    "            'Step09.03':\"Include Intercept value in Model: \", 'Step09.04':\"Magnitude of Iteration Limit: \",\n",
    "            'Step09.05':\"Percentile to use as Threshold for Binarization of Response Variable: \", \n",
    "            'Step09.06':\"Number of Layers in Model: \", 'Step09.07':\"Branches or Nodes per Layers of Model: \",\n",
    "            'Step09.08':\"Learning Rate of Model: \",\n",
    "            'Step12.01':\"Histogram of Response Variable Values\", 'Step12.02':\"Histogram(s) of Predictor Variable Values\",\n",
    "            'Step13':\"Table of Requested Measure(s)\",'Step14':\"Details of Requested Model\"};\n",
    "\n",
    "# globalized variables:\n",
    "# df_DataProc; df_Meas; df_Prop; df_Schema; \n",
    "# namesMeas; namesPred; namesProp; namesResp;\n",
    "# uniList\n",
    "\n",
    "def loadData():\n",
    "#. load data files into memory\n",
    "    global df_Cohorts; df_Cohorts = pd.read_csv(folder+'/'+files[0]); \n",
    "    global df_DataProc; df_DataProc = pd.read_csv(folder+'/'+files[1]);\n",
    "    global df_Meas; df_Meas = pd.read_csv(folder+'/'+files[2]); \n",
    "    global df_Prop; df_Prop = pd.read_csv(folder+'/'+files[3]);\n",
    "    global df_Schema; df_Schema = pd.read_csv(folder+'/'+files[4]);\n",
    "    global namesResp; namesResp = genFieldDict(['Response'],df_Schema); \n",
    "    global namesPred; namesPred = genFieldDict(['Predictor'],df_Schema);\n",
    "    global namesMeas; namesMeas = genFieldDict(['Ready'],df_Meas); \n",
    "    global namesProp; namesProp = genFieldDict(['Ready'],df_Prop);\n",
    "    global uniList; uniList = genFieldDict(['Variate'],df_Meas);\n",
    "\n",
    "def genFieldDict(reqList,df):\n",
    "#. generate field dictionary from dataframe based on specified parameter flag(s)\n",
    "    reqQuery = buildQuery(reqList);\n",
    "    fieldlist = df.query(reqQuery).Column.to_numpy();\n",
    "    fieldDict = dict(enumerate(fieldlist.flatten(), 1));\n",
    "    #fieldDictInv = dict((v, k) for k, v in fieldDictInv.items());\n",
    "    return fieldDict;\n",
    "    \n",
    "def buildQuery(colList,valList = [1], ander=True):\n",
    "    conj = \" and \" if ander else \" or \";\n",
    "    offset = len(conj); query = \"\"; eqstr = \" == \";\n",
    "    if (len(colList)>1):\n",
    "        if (len(valList)>1):\n",
    "            queryDict = dict(zip(colList,valList));\n",
    "        else:\n",
    "            queryDict = dict(zip(colList,valList*len(colList)));\n",
    "        for k,v in queryDict.items():\n",
    "            query = query + conj + k + eqstr + str(v);\n",
    "        query = query[offset:(len(query)-offset)];\n",
    "    else:\n",
    "        query = str(colList[0]) + eqstr + str(valList[0]);\n",
    "    return query;\n",
    "    \n",
    "def genMeas(varResp, varPred, varMeas):\n",
    "# pull specified values from data sources -> pass to measure switch -> pass back to view\n",
    "    retResp = {}; retVal = {}; measList = []; \n",
    "    for meas in varMeas:\n",
    "        measList.append(namesMeas[meas]);\n",
    "    respVals = df_DataProc[namesResp[varResp]];     \n",
    "    for meas in measList:\n",
    "        if (meas in uniList.values()):\n",
    "            retResp[meas] = calcSwitch(meas,respVals);\n",
    "    if (len(varPred)>0):\n",
    "        predDict = {};\n",
    "        for varP in varPred:\n",
    "            predName = namesPred[varP];\n",
    "            predVals = df_DataProc[predName];\n",
    "            retPredCurr = {}; \n",
    "            for meas in measList:\n",
    "                if (meas in uniList.values()):\n",
    "                    retPredCurr[meas] = calcSwitch(meas,predVals);\n",
    "                else:\n",
    "                    retPredCurr[meas] = calcSwitch(meas,predVals,respVals);            \n",
    "            predDict[predName] = retPredCurr;\n",
    "            retVal['pred'] = predDict;\n",
    "    retVal['resp'] = retResp;\n",
    "    return retVal;\n",
    "\n",
    "def calcSwitch(measName,varA,varB=[]):\n",
    "# identify measure -> pass values to measure-specific function -> format result as single string -> pass back to view\n",
    "    retVal = '';\n",
    "# Bivariate Measures\n",
    "    if (measName=='Chi-Squared-Independence'):\n",
    "        val,pval = calcChiSq(varA,varB);        \n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Correlation-Pearson'):\n",
    "        val,pval = calcCorrP(varA,varB);        \n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Correlation-Spearman'):\n",
    "        val,pval = calcCorrS(varA,varB);\n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Covariance'):\n",
    "        retVal = calcCovar(varA,varB);\n",
    "# Univariate Measures\n",
    "    elif (measName=='Interquartile-Range'):\n",
    "        retVal = calcIQR(varA);\n",
    "    elif (measName=='Kurtosis'):\n",
    "        retVal = calcKurtosis(varA);\n",
    "    elif (measName=='Maximum'):\n",
    "        retVal = calcMax(varA);\n",
    "    elif (measName=='Mean'):\n",
    "        retVal = calcMean(varA);\n",
    "    elif (measName=='Median'):\n",
    "        retVal = calcMedian(varA);\n",
    "    elif (measName=='Median-Absolute-Deviation'):\n",
    "        retVal = calcMAD(varA);\n",
    "    elif (measName=='Minimum'):\n",
    "        retVal = calcMin(varA);\n",
    "    elif (measName=='Mode'):\n",
    "        retVal = calcMode(varA);\n",
    "    elif (measName=='Normality'):\n",
    "        val,pval = calcNormality(varA,varB);\n",
    "        retVal = str(val)+\"(\"+str(pval)+\")\";\n",
    "    elif (measName=='Range'):\n",
    "        retVal = calcRange(varA);\n",
    "    elif (measName=='Relative-Standard-Deviation'):\n",
    "        retVal = calcRSD(varA);\n",
    "    elif (measName=='Skew'):\n",
    "        retVal = calcSkew(varA);\n",
    "    elif (measName=='Standard-Deviation'):\n",
    "        retVal = calcStd(varA);\n",
    "    return retVal;\n",
    "\n",
    "# BEGIN MEASURE-SPECIFIC FUNCTIONS\n",
    "# BEGIN BIVARIATE MEASURES\n",
    "def calcChiSq(varA,varB):\n",
    "    retV, retP, _, _ = chi2_contingency(np.array([varA,varB]), correction=False);\n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCorrP(varA,varB):\n",
    "    retV, retP = pearsonr(varA,varB); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCorrS(varA,varB):\n",
    "    retV, retP = spearmanr(varA,varB); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcCovar(varA,varB):\n",
    "    return round(np.cov(a,b)[0][1],MRL);\n",
    "\n",
    "# END BIVARIATE MEASURES\n",
    "# BEGIN UNIVARIATE MEASURES\n",
    "def calcIQR(varList):\n",
    "    return round(iqr(varList),MRL);\n",
    "\n",
    "def calcKurtosis(varList):\n",
    "    return round(kurtosis(varList),MRL);\n",
    "\n",
    "def calcMax(varList):\n",
    "    return round(max(varList),MRL);\n",
    "\n",
    "def calcMedian(varList):\n",
    "    return round(stttx.median(varList),MRL);\n",
    "\n",
    "def calcMAD(varList):\n",
    "    return round(median_abs_deviation(varList),MRL);\n",
    "\n",
    "def calcMean(varList):\n",
    "    return round(np.mean(varList),MRL);\n",
    "\n",
    "def calcMin(varList):\n",
    "    return round(min(varList),MRL);\n",
    "\n",
    "def calcMode(varList): \n",
    "    return round(mode(varList),MRL);\n",
    "\n",
    "def calcNormality(varList): #TODO\n",
    "    retV, retP = spearmanr(varList); \n",
    "    retV = round(retV,MRL);\n",
    "    retP = round(retP,MRL);\n",
    "    return [retV,retP];\n",
    "\n",
    "def calcRange(varList):\n",
    "    return round(calcMax(varList)-calcMin(varList),MRL);\n",
    "\n",
    "def calcRSD(varList):\n",
    "    return round(calcStd(varList)/calcMean(varList),MRL);\n",
    "\n",
    "def calcSkew(varList):\n",
    "    return round(skew(varList),MRL);\n",
    "\n",
    "def calcStd(varList):\n",
    "    return round(np.std(varList),MRL);\n",
    "# END UNIVARIATE MEASURES\n",
    "# END MEASURE-SPECIFIC FUNCTIONS\n",
    "\n",
    "def genModel(varResp, varPred, varProp, d_Conf):\n",
    "# pull specified values from data sources -> pass to model switch -> pass back to view\n",
    "    retVal = {}; \n",
    "    respName = namesResp[varResp]; valsResp = df_DataProc[respName];\n",
    "    valsPred = pd.DataFrame(); \n",
    "    for varP in varPred:\n",
    "        predName = namesPred[varP];\n",
    "        valsPred[predName] = df_DataProc[predName];\n",
    "    propName = namesProp[varProp];\n",
    "    retVal = modelSwitch(propName,valsResp,valsPred,d_Conf);\n",
    "    return retVal;\n",
    "\n",
    "def modelSwitch(propName,valsResp,valsPred,d_Conf):\n",
    "# identify proposition -> pass values and configuration to proposition-specific function -> calculate error rates -> pass back to view\n",
    "# TODO Display: Scatter plot(s) for Proposition:Linear Regression, Proposition:LDA, Proposition:SVM\n",
    "# Node-Graph for Proposition:Decision Tree and Proposition:Neural Network\n",
    "# Univariate: Box-and-whisker plot\n",
    "# Bivariate: Scatter Plots\n",
    "# TODO Propositions: Decision Tree (allows for inferences on Nominal data and has high interpretability)\n",
    "# Linear Discrimint Analysis\n",
    "# Support Vector Machine\n",
    "    retVal = {};\n",
    "    np.random.seed(d_Conf['Seed']); sample = np.random.uniform(size = len(valsResp.index)) < d_Conf['TrainPct'];\n",
    "    trainResp = valsResp[sample]; testResp = valsResp[~sample];\n",
    "    trainPred = valsPred[sample]; testPred = valsPred[~sample];\n",
    "    binclass = (df_Prop[df_Prop.Column==propName].Binthresh==1);\n",
    "    if(binclass):\n",
    "        thresh = np.percentile(valsResp,d_Conf['BinThresh']);\n",
    "        trainResp = (trainResp > thresh).astype(int); \n",
    "        testResp = (testResp > thresh).astype(int); \n",
    "    if (propName=='Neural-Network'):\n",
    "        model = modelNN(trainResp,trainPred,d_Conf);\n",
    "        retVal['model'] = model;\n",
    "        modTrain = model(convNNType(trainPred)).detach().numpy().T[0];\n",
    "        modTest =  model(convNNType(testPred)).detach().numpy().T[0];\n",
    "    else:\n",
    "        if (propName=='Decision-Tree'):\n",
    "            retVal['model'] = modelDecTree(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Linear-Discriminant-Analysis'):\n",
    "            retVal['model'] = modelLDA(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Linear-Regression'):\n",
    "            retVal['model'] = modelLinReg(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Logistic-Regression'):\n",
    "            retVal['model'] = modelLogReg(trainResp,trainPred,d_Conf);\n",
    "        elif (propName=='Support-Vector-Machine'):\n",
    "            retVal['model'] = modelLDA(trainResp,trainPred,d_Conf);\n",
    "        modTrain = retVal['model'].predict(trainPred);\n",
    "        modTest = retVal['model'].predict(testPred);\n",
    "    retVal['error'] = {};\n",
    "    retVal['error']['train'] = assessErr(trainResp.to_numpy(),modTrain,binclass);\n",
    "    retVal['error']['test'] = assessErr(testResp.to_numpy(),modTest,binclass);\n",
    "    if (binclass):\n",
    "        retVal['roc'] = {};\n",
    "        retVal['roc']['train'] = assessAUC(trainResp.to_numpy(),modTrain);\n",
    "        retVal['roc']['test'] = assessAUC(testResp.to_numpy(),modTest);\n",
    "    return retVal;\n",
    "\n",
    "# BEGIN PROPOSITION-SPECIFIC FUNCTIONS\n",
    "def modelDecTree(resp,pred,d_Conf):\n",
    "    model = tree.DecisionTreeClassifier(); \n",
    "    model.fit(pred,resp)\n",
    "    return model;\n",
    "\n",
    "def modelLDA(resp,pred,d_Conf):\n",
    "    model = lda.LinearDiscriminantAnalysis(tol=d_Conf['LearnRate']); \n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelLinReg(resp,pred,d_Conf):\n",
    "    model = lm.LinearRegression(fit_intercept=d_Conf['Intercept']);\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelLogReg(resp,pred,d_Conf):\n",
    "    model = lm.LogisticRegression(fit_intercept=d_Conf['Intercept'],max_iter=d_Conf['Magnitude']);\n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def modelSVM(resp,pred,d_Conf):\n",
    "    model = SVC(kernel='linear',max_iter=d_Conf['Magnitude'],tol=d_Conf['LearnRate']); \n",
    "    model.fit(pred,resp);\n",
    "    return model;\n",
    "\n",
    "def convNNType(df):\n",
    "    return torch.from_numpy(df.values).float();\n",
    "\n",
    "def modelNN(rdat,pdat,d_Conf):\n",
    "    pdat = convNNType(pdat); rdat = convNNType(rdat);\n",
    "    inSz = pdat.shape[1]; outSz = 1;\n",
    "    modelGraph = OrderedDict([('inLayer', nn.Linear(inSz,d_Conf['Nodes'])),('relu1', nn.ReLU())]);\n",
    "    if (d_Conf['Layers']>1):\n",
    "        for idx in range(1,d_Conf['Layers']):\n",
    "            modelGraph['hl'+str(idx)] = nn.Linear(d_Conf['Nodes'],d_Conf['Nodes']); \n",
    "            modelGraph['relu'+str(1+idx)] = nn.ReLU();\n",
    "    modelGraph['outLayer'] = nn.Linear(d_Conf['Nodes'],outSz); model = nn.Sequential(modelGraph);    \n",
    "    model.zero_grad(); lossFn = nn.MSELoss(reduction='sum');\n",
    "    optim = torch.optim.Adam(model.parameters(), d_Conf['LearnRate']);\n",
    "    for idx in range(d_Conf['Magnitude']):\n",
    "        currPred = model(pdat); currLoss = lossFn(currPred,rdat);\n",
    "        optim.zero_grad(); currLoss.backward(); optim.step();\n",
    "    return model; \n",
    "# END PROPOSITION-SPECIFIC FUNCTIONS\n",
    "\n",
    "def assessErr(truth,prediction,bindata=False):\n",
    "    if (bindata): # Percent Error\n",
    "        retVal = sum(abs(np.subtract(truth,prediction))/len(truth));\n",
    "    else: # RMS Error\n",
    "        retVal = round(math.sqrt(sum((np.subtract(truth,prediction))**2)/len(truth)),2);\n",
    "    return retVal; \n",
    "\n",
    "def assessAUC(truth,prediction):\n",
    "    fpr, tpr, thresh = roc_curve(truth,prediction); calcAUC = auc(fpr, tpr); \n",
    "    return [fpr,tpr,calcAUC];\n",
    "\n",
    "def makeROC(inDict,title):\n",
    "    fig = go.Figure();\n",
    "    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], line={'color':'navy','width':2}));\n",
    "    fig.add_trace(go.Scatter(x=inDict[0], y=inDict[1], line={'color':'darkorange','width':2,'dash':'dash'}));\n",
    "    fig.update_layout(title=('ROC curve (area = '+str(round(inDict[2],MRL))+') for '+title)\n",
    "                   ,xaxis_title='False Positive Rate'\n",
    "                   ,yaxis_title='True Positive Rate')\n",
    "    return fig;\n",
    "\n",
    "def setDiff(listA,listB):\n",
    "    return list(set(listA) - set(listB));\n",
    "\n",
    "def setInt(listA,listB):\n",
    "    return list(set(listA) & set(listB));\n",
    "# END LOGIC FUNCTIONS\n",
    "\n",
    "loadData(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a0fa20-f600-45ae-839e-0cf70a7eaf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: dash_useful_components in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: flask in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: IPython in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (8.2.0)\n",
      "Requirement already satisfied: Markup in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.2)\n",
      "Requirement already satisfied: matplotlib in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.5.1)\n",
      "Requirement already satisfied: networkx in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (2.7.1)\n",
      "Requirement already satisfied: numpy in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (1.21.5)\n",
      "Requirement already satisfied: pandas in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: plotly in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (5.6.0)\n",
      "Requirement already satisfied: requests in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (2.27.1)\n",
      "Requirement already satisfied: seaborn in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (0.11.2)\n",
      "Requirement already satisfied: scipy in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.7.3)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting statistics\n",
      "  Using cached statistics-1.0.3.5.tar.gz (8.3 kB)\n",
      "Requirement already satisfied: statsmodels in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (0.13.2)\n",
      "Requirement already satisfied: tensorflow in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 18)) (2.9.1)\n",
      "Requirement already satisfied: torch in d:\\working\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 19)) (1.11.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: dash-table==5.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from dash->-r requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: flask-compress in d:\\working\\anaconda3\\lib\\site-packages (from dash->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from dash->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from dash->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: click>=5.1 in d:\\working\\anaconda3\\lib\\site-packages (from flask->-r requirements.txt (line 3)) (8.0.4)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in d:\\working\\anaconda3\\lib\\site-packages (from flask->-r requirements.txt (line 3)) (2.0.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in d:\\working\\anaconda3\\lib\\site-packages (from flask->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in d:\\working\\anaconda3\\lib\\site-packages (from flask->-r requirements.txt (line 3)) (2.11.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (3.0.20)\n",
      "Requirement already satisfied: stack-data in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (61.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.18.1)\n",
      "Requirement already satisfied: decorator in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: backcall in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (2.11.2)\n",
      "Requirement already satisfied: colorama in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.4.4)\n",
      "Requirement already satisfied: traitlets>=5 in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in d:\\working\\anaconda3\\lib\\site-packages (from IPython->-r requirements.txt (line 4)) (0.7.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\working\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\working\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 9)) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\working\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 10)) (8.0.1)\n",
      "Requirement already satisfied: six in d:\\working\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\working\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 11)) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\working\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 11)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\working\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 11)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from requests->-r requirements.txt (line 11)) (2.0.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\working\\anaconda3\\lib\\site-packages (from sklearn->-r requirements.txt (line 14)) (1.0.2)\n",
      "Requirement already satisfied: docutils>=0.3 in d:\\working\\anaconda3\\lib\\site-packages (from statistics->-r requirements.txt (line 15)) (0.17.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in d:\\working\\anaconda3\\lib\\site-packages (from statsmodels->-r requirements.txt (line 16)) (0.5.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (14.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.42.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (0.26.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (4.1.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.12.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (3.19.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\working\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 18)) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\working\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 18)) (0.37.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\working\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 4)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\working\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: wcwidth in d:\\working\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->-r requirements.txt (line 4)) (0.2.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\working\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\working\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\working\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\working\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\working\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\working\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\working\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\working\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 18)) (3.2.0)\n",
      "Requirement already satisfied: brotli in d:\\working\\anaconda3\\lib\\site-packages (from flask-compress->dash->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\working\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->-r requirements.txt (line 14)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\working\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->-r requirements.txt (line 14)) (2.2.0)\n",
      "Requirement already satisfied: executing in d:\\working\\anaconda3\\lib\\site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\working\\anaconda3\\lib\\site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\working\\anaconda3\\lib\\site-packages (from stack-data->IPython->-r requirements.txt (line 4)) (0.2.2)\n",
      "Building wheels for collected packages: sklearn, statistics\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=5185367f38ef615806d39655ab706f8981fb9ffad2823f1e7b51ccbfd5f08134\n",
      "  Stored in directory: c:\\users\\19734\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "  Building wheel for statistics (setup.py): started\n",
      "  Building wheel for statistics (setup.py): finished with status 'done'\n",
      "  Created wheel for statistics: filename=statistics-1.0.3.5-py3-none-any.whl size=7454 sha256=d8d660a7944c07e796469820c281ef6069ca7c29f11b95e7469adb3150d7e983\n",
      "  Stored in directory: c:\\users\\19734\\appdata\\local\\pip\\cache\\wheels\\26\\3c\\70\\9467407f3aa90862061eadcd286627b23a8bab6789b667776f\n",
      "Successfully built sklearn statistics\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Installing collected packages: torchvision, statistics, sklearn\n",
      "Successfully installed sklearn-0.0 statistics-1.0.3.5 torchvision-0.12.0\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2d088-dc9e-44f1-88b7-8a7da451a875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
